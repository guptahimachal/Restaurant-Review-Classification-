{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow... Loved this place.\n",
      "Wow... Loved this place.\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset=pd.read_csv('Restaurant_Reviews.tsv' , delimiter='\\t' , quoting =3) #for ignoring double \"\n",
    "# Analyzing the dataset\n",
    "print(dataset.values[0][0])\n",
    "print(dataset['Review'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Cleaning the Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HimachalGupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# re library is used for better searching ,\n",
    "# among its other application one that we use here is split\n",
    "import re\n",
    "# NLTK (Natural Language Toolkit)\n",
    "import nltk\n",
    "# stopwords will remove the Unwanted words like the,they etc \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# Stemming is a technique where a set of words in a sentence\n",
    "# are converted into a sequence to shorten its lookup\n",
    "\n",
    "# corpus will be our final requirement for bag of words\n",
    "corpus = []    \n",
    "\n",
    "# Iterating For every sample data \n",
    "for i in range (0,1000):\n",
    "    # replaces the substring not haveing characters (a-z or A-Z) with ' '\n",
    "    review = re.sub('[^a-zA-Z]' ,' ', dataset['Review'][i])\n",
    "    # Makes the substrings into lower cases\n",
    "    review = review.lower()\n",
    "    # Makes each remaining sentence into list(object) of words(string) \n",
    "    review = review.split()                                 \n",
    "    # For each word not present in stopwords it stem the word\n",
    "    ps=PorterStemmer()\n",
    "    review=[ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    # Joining the list element back into string\n",
    "    review = ' '.join(review)\n",
    "    # Appending it to our corpus\n",
    "    corpus.append(review)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the bag of words model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Bag of Words Model is a sparse matrix where each row is the review and each column is a unique \n",
    "# word from the reviews.\n",
    "# Tokenization is the process of taking all unique words of reviews and creating columns for each word.\n",
    "# Since this a problem of classification we have dependent and independent variables and each \n",
    "# unique word/column is like an independent variable and the review(good/bad) depends on these words\n",
    "# Making the Bag of words with 1500 Most frequent words as features \n",
    "# and each data-set will be defined by token if a word in it matches these \n",
    "# 1500 words\n",
    "cv = CountVectorizer(max_features = 1500) \n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "# making matrix of dependent variable (Positive or negative values)\n",
    "Y = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the top 20 Words as Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = CountVectorizer(max_features = 1500).fit(corpus)\n",
    "bag_of_words = vec.transform(corpus)\n",
    "sum_words = bag_of_words.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "indexes=[word[1] for word in words_freq]\n",
    "values =[word[0] for word in words_freq]\n",
    "indexes = indexes[:20]\n",
    "values  = values [:20]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(values, indexes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into training-set and test-set and applying various ML Classification Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into test set and training set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size=0.20 , random_state=0)\n",
    "cm_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Logistic Regression\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting Logistic Regression to training set\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier=LogisticRegression ( random_state=0 )\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    \n",
    "    # PRedicting the cm_list\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm     \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying KNN\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting KNN to training set\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    \n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm     \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying SVM Linear\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting SVM Linear to training set\n",
    "    from sklearn.svm import SVC\n",
    "    classifier=SVC(kernel='linear',random_state=0) \n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying SVM Gaussian Kernel\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting SVM to training set\n",
    "    from sklearn.svm import SVC\n",
    "    classifier=SVC(kernel='rbf',random_state=0) \n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying SVM Polynomial Kernel\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting SVM to training set\n",
    "    from sklearn.svm import SVC\n",
    "    classifier=SVC(kernel='poly',random_state=0) \n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying SVM Sigmoid Kernel\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting SVM to training set\n",
    "    from sklearn.svm import SVC\n",
    "    classifier=SVC(kernel='sigmoid',random_state=0) \n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying Naive bayes\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting Naive Bayes to training set\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier=GaussianNB() \n",
    "    classifier.fit(X_train,Y_train)\n",
    "    \n",
    "    # PRedicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm     \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "        \n",
    "# Applying Decision Tree\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting Decision Tree to training set\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n",
    "\n",
    "# Applying Random Forest Tree\n",
    "def model(X_train , X_test , Y_train , Y_test):\n",
    "    # Fitting Decision Tree to training set\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier=RandomForestClassifier(n_estimators=10 , criterion='entropy' , random_state=0)\n",
    "    classifier.fit(X_train,Y_train)\n",
    "\n",
    "    # Predicting the result\n",
    "    Y_pred=classifier.predict(X_test)\n",
    "      \n",
    "    # Making the Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm=confusion_matrix(Y_test,Y_pred)\n",
    "    return cm  \n",
    "cm_list.append(model(X_train , X_test , Y_train , Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>66</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.694737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.466019</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM-Linear</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM-Gaussian</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM-Poly</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM-Sigmoid</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.771186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.701031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.670588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  TN  FP   FN  TP  Accuracy  Precision    Recall  \\\n",
       "0  Logistic Regression  76  21   37  66     0.710   0.758621  0.640777   \n",
       "1                  KNN  74  23   55  48     0.610   0.676056  0.466019   \n",
       "2           SVM-Linear  74  23   33  70     0.720   0.752688  0.679612   \n",
       "3         SVM-Gaussian  97   0  103   0     0.485        NaN  0.000000   \n",
       "4             SVM-Poly  97   0  103   0     0.485        NaN  0.000000   \n",
       "5          SVM-Sigmoid  97   0  103   0     0.485        NaN  0.000000   \n",
       "6          Naive Bayes  55  42   12  91     0.730   0.684211  0.883495   \n",
       "7        Decision Tree  74  23   35  68     0.710   0.747253  0.660194   \n",
       "8        Random Forest  87  10   46  57     0.720   0.850746  0.553398   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.694737  \n",
       "1  0.551724  \n",
       "2  0.714286  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "5       NaN  \n",
       "6  0.771186  \n",
       "7  0.701031  \n",
       "8  0.670588  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[[]]\n",
    "for i in range (0,9):\n",
    "    tmp=[]\n",
    "    for j in range (0,2):\n",
    "        for k in range (0,2):\n",
    "            tmp.append(cm_list[i][j][k])        \n",
    "    tmp.append(   (tmp[0]+tmp[3])/(tmp[0]+tmp[1]+tmp[2]+tmp[3])    )  # Accuracy\n",
    "    tmp.append(   tmp[3]/(tmp[3]+tmp[1])   )                          # Precision\n",
    "    tmp.append(   tmp[3]/(tmp[3]+tmp[2])   )                          # Recall\n",
    "    tmp.append(   (2*tmp[5]*tmp[6])/(tmp[5]+tmp[6])  )                # F1 Score\n",
    "    result.append(tmp)\n",
    "result.remove([])        \n",
    "\n",
    "result = pd.DataFrame(result , columns=['TN','FP','FN','TP','Accuracy','Precision','Recall','F1 Score'])\n",
    "\n",
    "df = pd.DataFrame(columns=['Model Name'])\n",
    "value=[\"Logistic Regression\",'KNN','SVM-Linear','SVM-Gaussian',\n",
    "                                  'SVM-Poly','SVM-Sigmoid','Naive Bayes','Decision Tree',\n",
    "                                  'Random Forest']\n",
    "for i in range (0,9):\n",
    "    df = df.append({'Model Name' : value[i]}, ignore_index=True)        \n",
    "\n",
    "result=pd.concat([df,result],axis=1)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
